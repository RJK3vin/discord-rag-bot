# Document 1 content Intern FAQ
DOCUMENT_1 = """
AI Bootcamp - Intern Onboarding Summary

📌 Mandatory Steps:
- Watch onboarding video from Dr. Nancy Li.
- Join the Developer Discord:
  • Update your name and LinkedIn in your profile.
  • Introduce yourself in #networking.
  • Post your tech stack in #techstack.

📺 Watch These:
- Cohort 1 & 2 Demo: https://youtu.be/S69147JbQpU
- Cohort 3 Demo: https://youtu.be/5OZjUtUdbbI

📚 Training & Mentor Sessions:
- Join tech mentor sessions (announced on Discord).
- Use playlists for training:
  • Engineers' Training
  • Designers' Training

🧑‍💻 Team Matching:
- Week 2: PMs pitch to Designers.
- Week 4: PMs + Designers pitch to Engineers.
  → Engineers submit tech stack, rank top 3 projects, and indicate Lead interest.

📆 Internship Timeline:
- Weeks 1-4: Onboarding, training, team matching.
- Weeks 5-8: Build MVP with team.
- Weeks 9-10: Test features, finalize product.

💬 Communication:
- Use Discord for all questions. Tag Marla for ops help.
- Do NOT DM Dr. Nancy Li.

🏅 Intern Awards:
🥇 AI Trailblazer - Led innovation & exceeded expectations.
🥈 AI Innovator - Delivered solid contributions.
🥉 AI Rising Star - Showed growth & consistency.

All awards include:
- LinkedIn badge + AI certificate
- Team lead recommendation
- Potential job referrals

🌍 Visa / CPT / OPT Notes:
- Start/end dates must closely align with cohort.
- Ask your school first, then notify support.
- Use #visa-sponsorship channel for questions.

📌 FAQ Highlights:
- Unpaid, min 10 hrs/week commitment.
- Public GitHub required for code review.
- Use any tech stack (Python preferred).
- API/tools allowed. Projects vary (AI bots, pricing tools, etc.).
- Certification & job referrals available post-internship.
"""

# Document 2 content AI Engineers
DOCUMENT_2 = """
Key Technical Knowledge for AI Engineers

🧠 Core AI Concepts:
- Machine Learning: Learning patterns from data.
- Deep Learning: Neural networks with multiple layers.
- NLP (Natural Language Processing): Understand human language.
- Transformers: Introduced by Google's “Attention is All You Need.”
- Computer Vision: Analyze visual information.
- LLMs (Large Language Models): Pre-trained models like ChatGPT.
- Tokens: Numerical text units (~4 characters = 1 token).
- Context Window: Token capacity an LLM can process.
- Hallucinations: LLMs generating incorrect output.
- Prompt Engineering: Optimizing questions for better AI output.
- RAG (Retrieval-Augmented Generation): External knowledge + LLMs.
- Conversational Agents: Multi-agent systems for enhanced reasoning.
- FastAPI: Python API framework.
- Docker: Containerization for reproducibility.

🛠 Tools & Frameworks:
- OpenAI, Azure OpenAI, Hugging Face, Langchain, CrewAI
- LangChain Agents: Tool-using LLM bots
- LangGraph: Multi-agent workflows and evaluations

📚 Advanced AI Concepts:
- Overfitting vs Underfitting
- Bias, Variance, and Feature Engineering
- Hyperparameter Tuning & Model Deployment
- MLOps: DevOps for ML - ZoomCamp 9-week course
- Task Framing & Data Cleaning (Production environments)
- Sampling frequency and data labeling
- Supervised Learning: Classification, Regression, NER, Object Detection
- Unsupervised Learning: Clustering, Dimensionality Reduction
- Reinforcement Learning: Reward-based learning (e.g., OpenAI Hide & Seek)
- GANs: Generative Adversarial Networks
- RLHF: Reinforcement Learning with Human Feedback
- Model Distillation & Quantization
- Fine-Tuning & Catastrophic Forgetting
- Self-hosting LLMs

🤖 Agent Strategies:
- Reflection, Tool Use, Planning, Multi-Agent Collaboration
- UX for Agents (LangChain examples)

🧑‍💻 Practical Applications:
- Build ChatGPT apps using Flask & OpenAI API
- Combine ChatGPT with DALL-E
- Learn SQL (basics to advanced)
- Database Design, Normalization, ER Diagrams
- Python Fundamentals (Pandas, NumPy)
- Python + Database integration (SQLAlchemy, psycopg2)

🗃 Developer Foundations:
- Microsoft DB Basics
- SQL Reference Docs
- Logical DB Design (32 min video)
- Meta's 27-hour intro to databases (optional)
- Python for Beginners (3h55m)
- Python Libraries for Data Science (1h49m)
- Connecting Python to SQL (8-17 mins)

Note: Many topics have corresponding video tutorials or docs. Refer to original material or internal bootcamp resources for links.
"""

# Document 3 content AI Bootcamp
DOCUMENT_3 = """
Bootcamp Journey Overview

Covers:
- Technical Skills Development
- Core ML/AI Concepts
- Gen AI & Data Engineering
- MLOps & Deployment
- Project-Based Learning
- Agile Scrum
- Team Collaboration & Real-World Apps

📆 Project Timeline (11 Weeks):
Week 1-2: Onboarding, AI Training (Engineers & Designers), Join office hours.
  - Engineers: Job Tracker / FAQ Chatbot
  - Designers: Pitch Day + Team Match (fill Team Match.xls)

Week 3: Continue development
  - Designers: High-Fidelity Designs, Interviews
  - Engineers: Job Tracker / FAQ Chatbot

Week 4: Zoom Pitch Day + Engineer Rankings
  - PMs & Designers present ideas, Engineers rank preferred teams

Weeks 5-9: Agile collaboration in cross-functional teams
Week 10: Testing + Finalization
Week 11: Final Demo

📚 Training Modules

🧠 Technical Skills (Weeks 1-2)
- ML Fundamentals: Neural nets, propagation, activations, loss
- Transformers: Self-attention, multi-head attention
- Deep Learning: Transfer learning, pre-trained models, metrics
- Hands-On: PyTorch, model training

Resources: Illustrated Transformer, Karpathy's Zero to Hero, HuggingFace NLP Course

🤖 Gen AI & Data Engineering (4 Days)
- LLMs, prompt engineering, RAG, vector DBs
- Data preprocessing, chunking, embeddings, validation
- API integration, error handling, cost optimization

Resources: LangChain docs, OpenAI Cookbook, Pinecone vector DB overview

⚙️ MLOps & Deployment (3 Days)
- Git workflow, code reviews, testing, documentation
- Docker, CI/CD, model serving (FastAPI)
- Monitoring: logs, performance, cost

Resources: MLOps Zoomcamp, FastAPI Docs, Docker for ML

🧪 Project-Based Learning (Weeks 3-11)
Agile Scrum Framework:
- 1-2 week sprints, daily standups, sprint planning/review/retros
- Document backlog, user stories, technical & deployment docs
- Tools: GitHub, JIRA/Monday, docs of choice

👥 Team Roles:
- Fullstack, Frontend, Backend, Data Engineer, Data Scientist, UX, PM

Weekly Rhythm (flexible by team):
- Mon: Sprint planning
- Daily: Standups
- Wed: Technical review
- Fri: Demo + Docs

🚀 Deliverables:
- Working prototype, documented code, deployment pipeline, final pitch
- Focus: Business value, scalability, cost, UX, security

📺 Mentor Sessions (Kat Sao - Cohort 3):
- Wk1 Intro: https://youtu.be/_v6hyhS_U0U
- Wk3 Team Match Q&A: https://youtu.be/d7bCIwlXZsY
- Wk4 AI Product Lifecycle: https://youtu.be/sc8g3RvwBBk
- Wk5 Delivering Value: https://youtu.be/ADjjqyM1zP4
- Wk10 Final Demo Practice: Canceled

📊 Success Metrics:
- Functional prototype
- Clean, tested, documented code
- Strong team collaboration
- Final presentation

Training Docs:
- Engineer Training
- Designer Training
- Tools & Tech: [05. Tools & Technologies.docx]

Onboarding Video by Anil Thomas:
https://youtu.be/ZBEoZYmMCMc
"""

def retrieve_context_with_keywords(query: str) -> str:
    query_keywords = [word.lower() for word in query.split() if len(word) > 2]
    relevant_docs = []
    
    documents = [
        ("Document 1", DOCUMENT_1),
        ("Document 2", DOCUMENT_2), 
        ("Document 3", DOCUMENT_3)
    ]
    
    for doc_name, content in documents:
        content_lower = content.lower()
        # Check if any keywords are in this document
        if any(keyword in content_lower for keyword in query_keywords):
            relevant_docs.append(f"=== {doc_name} ===\n{content.strip()}")
    
    # If no documents match keywords, return all documents
    if not relevant_docs:
        all_content = [
            f"=== Document 1 ===\n{DOCUMENT_1.strip()}",
            f"=== Document 2 ===\n{DOCUMENT_2.strip()}",
            f"=== Document 3 ===\n{DOCUMENT_3.strip()}"
        ]
        return "\n\n".join(all_content)
    
    full_context = "\n\n".join(relevant_docs)
    
    max_length = 8000
    if len(full_context) > max_length:
        full_context = full_context[:max_length] + "... [Content truncated]"
    
    return full_context